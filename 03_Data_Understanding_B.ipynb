{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78da626b-7d05-4bc8-8204-27ba6c010209",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4d0ac4-226e-4f5b-a6fa-0bd1b85bd29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrameReader\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import IndexToString, Normalizer, StringIndexer, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from helpers.helper_functions import translate_to_file_string\n",
    "from pyspark.sql.functions import col,lit,to_date\n",
    "from pyspark.sql.functions import expr,when\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from sklearn.impute import KNNImputer\n",
    "from pyspark.sql.functions import rand, desc\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import MinHashLSH\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from IPython.display import display, clear_output\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "# for pretty printing\n",
    "def printDf(sprkDF): \n",
    "    newdf = sprkDF.toPandas()\n",
    "    from IPython.display import display, HTML\n",
    "    return HTML(newdf.to_html())\n",
    "\n",
    "inputFile = translate_to_file_string(\"./data/Data_Preparation_Result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4978b0a3-e029-4a47-addf-3d03cc69e0fd",
   "metadata": {},
   "source": [
    "## Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da5ee7-f795-4e20-8ea6-17affdfde647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a SparkSession\n",
    "spark = (SparkSession\n",
    "       .builder\n",
    "       .appName(\"RKICOVID19PREPARATION\")\n",
    "       .getOrCreate())\n",
    "# create a DataFrame using an ifered Schema \n",
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "       .option(\"inferSchema\", \"true\") \\\n",
    "       .option(\"delimiter\", \",\") \\\n",
    "       .csv(inputFile)   \n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83223f21-ba3e-4034-a6e5-a79408cbfc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lagemaße\n",
    "Nachfolgend werden verschiedene Lage-Maße des Datensatzes ermittelt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
