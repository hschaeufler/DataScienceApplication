{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78da626b-7d05-4bc8-8204-27ba6c010209",
   "metadata": {},
   "source": [
    "# Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4d0ac4-226e-4f5b-a6fa-0bd1b85bd29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from helpers.helper_functions import translate_to_file_string\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "inputFile = translate_to_file_string(\"./data/Data_Preparation_Result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4978b0a3-e029-4a47-addf-3d03cc69e0fd",
   "metadata": {},
   "source": [
    "## Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67da5ee7-f795-4e20-8ea6-17affdfde647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Bundesland: string (nullable = true)\n",
      " |-- BundeslandIndex: integer (nullable = true)\n",
      " |-- Landkreis: string (nullable = true)\n",
      " |-- LandkreisIndex: integer (nullable = true)\n",
      " |-- Altersgruppe: string (nullable = true)\n",
      " |-- AltersgruppeIndex: double (nullable = true)\n",
      " |-- Geschlecht: string (nullable = true)\n",
      " |-- GeschlechtIndex: double (nullable = true)\n",
      " |-- FallStatus: string (nullable = true)\n",
      " |-- FallStatusIndex: double (nullable = true)\n",
      " |-- Falldatum: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#create a SparkSession\n",
    "spark = (SparkSession\n",
    "       .builder\n",
    "       .appName(\"DataModelling\")\n",
    "       .getOrCreate())\n",
    "# create a DataFrame using an ifered Schema \n",
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "       .option(\"inferSchema\", \"true\") \\\n",
    "       .option(\"delimiter\", \";\") \\\n",
    "       .csv(inputFile)   \n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e88e9f4-6c6e-4171-b03b-c23335b53207",
   "metadata": {},
   "source": [
    "## Vorbereitung der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaafbf7-bf81-46f4-b14f-8bbdf3bb599b",
   "metadata": {},
   "source": [
    "### Filtern der Datensätze\n",
    "Für das Training dieses Modells ist es sinnvoll nur die Fälle zu betrachten, bei den der Ausgang der Corona-Erkrankung bereits bekannt ist (\"GENESEN\" oder \"GESTORBEN\"). Daher werden die Fälle mit noch erkrankten Personen herausgefiltert. Ebenfalls muss der FallStatusIndex neu vergeben werden, damit dieses Feature nur noch die Werte 0 oder 1 enthält."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89cc8a37-30ad-4458-8df2-ec4da36d7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNeu = df.filter(df.FallStatus != \"NICHTEINGETRETEN\").drop(\"FallStatusIndex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92173359-0c5a-432a-9442-7f7fd9f68d3e",
   "metadata": {},
   "source": [
    "### FallStatusIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c51fc4-9b1f-494e-807a-891dcfa54262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wollten eigentlich den Indexer mitgeben in die Pipeline. Dies führt aber zum Fehler, dass er das Label nicht kennt.\n",
    "indexer = StringIndexer(inputCol=\"FallStatus\", outputCol=\"FallStatusIndex\")\n",
    "dfReindexed = indexer.fit(dfNeu).transform(dfNeu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e99c5d-fcdd-4f62-8807-b810e4656ccc",
   "metadata": {},
   "source": [
    "### Ziehen eines Samples\n",
    "Da der Datensatz sehr groß ist, kommt es tlw. während dem Berechnen der Statistiken mittels der Multiclass-Metrics zu Problemen. Die Statistik enthält dann nur Nullwerte. Daher wird vorher ein Sample aus dem Datensatz gezogen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05275d56-19b4-4d48-861a-400376068db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsample = dfReindexed.sample(withReplacement=False, fraction=0.01, seed=12334556)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ce0a92-b723-4e40-82d9-98d92966e854",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "Ähnlich dem Fraud-Detection-Beispiel von Tara Boyle (2019) ist die Klasse der an Corona-Verstorbenen im vorliegenden Datensatz unterrepresentiert, weshalb man an dieser Stelle von einer Data Imbalance spricht. Dies sieht man wenn man die Anzahl der Todesfälle mit den Anzahl der Genesenen vergleicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38aea32c-b5d9-45b1-98c8-312f0c3bd786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|FallStatus|count|\n",
      "+----------+-----+\n",
      "|   GENESEN|34657|\n",
      "| GESTORBEN|  950|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vergleich der Fallzahlen\n",
    "dfsample.groupBy(\"FallStatus\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c742d2-ae43-405b-b7ca-152152aa8c25",
   "metadata": {},
   "source": [
    "Die meisten Machine Learning Algorithmen arbeiten am Besten wenn die Nummer der Samples in allen Klassen ungefähr die selbe größe haben. Dies konnte auch im Zuge dieser Arbeit bei den unterschiedlichen Regressions-Modellen festgestellt werden. Da die einzelnen Modelle versuchen den Fehler zu reduzieren, haben alle Modelle am Ende für einen Datensatz nur die Klasse Genesen geliefert, da hier die Wahrscheinlichkeit am größten war korrekt zu liegen. \n",
    "Um diese Problem zu lösen gibt es zwei Möglichkeiten: Under- und Oversampling. Beides fällt unter den Begriff Resampling\n",
    "Beim Undersampling werden aus der Klasse mit den meisten Instanzen, Datensätze gelöscht, wohingegen beim Oversampling, der Klasse mit den wenigsten Isntanzen, neue Werte hinzugefügt werden. (Will Badr 2019; Tara Boyle 2019)\n",
    "Da in diesem Fall ausreichend Datensätze vorhanden sind, bietet sich Ersteres an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ac18099-9343-4a76-a5a1-3136c9a0f85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Gestorben : 950\n"
     ]
    }
   ],
   "source": [
    "# Ermittlung der Anzahl dr Verstorbenen\n",
    "dfGestorben = dfsample.filter(dfsample.FallStatus == \"GESTORBEN\")\n",
    "anzahlGestorben = dfGestorben.count()\n",
    "print(\"Anzahl Gestorben : %s\" % anzahlGestorben)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "851c2b85-cbbf-45e3-a315-c4d26cf79085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Genesen : 34657\n",
      "Verhältnis : 0.027411489742331995\n"
     ]
    }
   ],
   "source": [
    "# Ermittlung des Verhätlnisses von Verstorben und Gensen\n",
    "dfGenesen = dfsample.filter(dfsample.FallStatus == \"GENESEN\")\n",
    "anzahlGenesen = dfGenesen.count()\n",
    "print(\"Anzahl Genesen : %s\" % anzahlGenesen)\n",
    "\n",
    "ratio = anzahlGestorben / anzahlGenesen\n",
    "print(\"Verhältnis : %s\" % ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c753f487-04c8-41a4-8862-97169d570cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ziehen eines Samples mit der näherungsweise selben Anzahl wie Verstorbene\n",
    "dfGenesenSample = dfGenesen.sample(fraction=ratio, seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e1ef4b7-7acb-430e-95aa-74927e6ef63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|FallStatus|count|\n",
      "+----------+-----+\n",
      "|   GENESEN|  926|\n",
      "| GESTORBEN|  950|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfGesamtSample = dfGestorben.union(dfGenesenSample)\n",
    "# Kontrolle\n",
    "dfGesamtSample.groupBy(\"FallStatus\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475de71e-da5c-49df-bc2d-6a1a30a8179b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Splitten in Trainings und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a43cb6d-a5e3-454d-a9bb-8a0f52886d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = dfGesamtSample.randomSplit([0.8, 0.2], 345678)\n",
    "trainingData = splits[0]\n",
    "testData = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b11078-4d6f-4903-86b7-803f96276072",
   "metadata": {},
   "source": [
    "### Aufbau des Feature-Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a9ed842-1619-4fc2-84ae-167971292725",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler =  VectorAssembler(outputCol=\"features\", inputCols=[\"GeschlechtIndex\",\"AltersgruppeIndex\", \"LandkreisIndex\",\"BundeslandIndex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a136e3f2-1007-4f62-9f35-d52869cd842c",
   "metadata": {},
   "source": [
    "## Modellierung\n",
    "### Logistic Regression\n",
    "Logistic Regression ist eine sehr beliebte Methode um Kategorien vorherzusagen. Für Binäre Werte ist eine Binominal Logistic Regresision anzuwenden. (Apache Spark 2021a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5006ea64-b3dc-4658-9b12-ab1b2e16ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10, featuresCol=\"features\", family=\"binomial\", labelCol=\"FallStatusIndex\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d5034e-f0cc-4e55-ba25-1482b964d471",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "030efbf4-d50a-4fc9-8448-61314a82c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler,lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eac72c-a03c-458d-a92f-c2d55ebba0c1",
   "metadata": {},
   "source": [
    "### Evaluator\n",
    "Für die spätere Cross-Validaton wird ein Evaluator benötigt. Letzterer ist zu wählen, abhängig von dem jeweilligen Modell und Anwendungsfall. (Apache Spark 2020a) In diesem Fall wird ein BinaryClassificationEvaluator angewendet. Dieser eignet sich besonders für binäre Werte. (Apache Spark 2021a) Da Geschlecht, in diesem Fall, der FallStatus 0 oder 1 annehmen kann, bietet er sich hier besonders an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55502289-015a-481b-92f1-8a7aefbad4a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BinaryClassificationEvaluator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ebf038ef95e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Definition des Evaluators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluator\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mBinaryClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"FallStatusIndex\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrawPredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetricName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"areaUnderPR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'BinaryClassificationEvaluator' is not defined"
     ]
    }
   ],
   "source": [
    "# Definition des Evaluators\n",
    "evaluator= BinaryClassificationEvaluator(labelCol=\"FallStatusIndex\",rawPredictionCol=\"prediction\", metricName=\"areaUnderPR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9b0dab-06d4-4d34-851c-558dcac729e2",
   "metadata": {},
   "source": [
    "### Parametertuning\n",
    "Eine wichtige Aufgabe beim Machine Learning ist die Auswahl des geeigneten Modells bzw. die passenden Paramter für ein Modell herauszufinden. Letzteres wird auch Parametertuning genannt. Die in Pyspark enthaltene MLLib bietet speziell hierfür ein entsprechende Tooling. Und zwar kann ein CrossValidator bzw. ein TrainValidationSplit verwendet werden. Voraussetzung sind ein Estimator (ein Modell oder eine Pipeline), ein Paramter-Grid und eine Evaluator. Dies ist auch im Zusammenhang mit dem Thema Cross-Validation zu sehen. (Apache Spark 2020a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a1571-498e-4d42-8f08-05500cacf6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.3,0.01]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.8])\\\n",
    "    .addGrid(evaluator.metricName, [\"areaUnderPR\", \"areaUnderROC\"])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431859e4-d239-447c-bf75-6f8437a36d82",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df713c9-41e8-4492-bcc5-77e3f5799d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition des Cross-Validators \n",
    "# num-Folds gibt an in wie viele Datensatz-Paare die Datensätze aufgeteilt werden.\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2,\n",
    "                          parallelism=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1efc88e-ebaa-4ada-befe-86ed11887356",
   "metadata": {},
   "source": [
    "#### Durchführung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e278a6a5-2976-411c-83bf-81d1227e4d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anpassung des Modells und Auswahl der besten Parameter\n",
    "cvModel = crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc1cdb4-de36-4db7-8e3b-9eb2aa5e91bb",
   "metadata": {},
   "source": [
    "### Testen des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457e7487-3f6c-4ae4-9a68-10abcafd09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cvModel.transform(testData)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b7acd-3978-40af-9842-295bd6c55792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kontrolle der Predictions\n",
    "predictions.groupBy(\"FallStatusIndex\", \"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7acaa7a-23f6-4d6c-a4ba-46ccf15dbe34",
   "metadata": {},
   "source": [
    "## Modell - Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ba7c7c-b146-4d1b-b21a-e02f5d5ef1bd",
   "metadata": {},
   "source": [
    "Area Under PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6d878-349d-439b-b985-db71d6f259d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error\",(1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec549f76-9a06-401b-93bf-50a5abce2b69",
   "metadata": {},
   "source": [
    "### BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a47263c-7e44-4b7a-ba63-3c4ac48832e1",
   "metadata": {},
   "source": [
    "Bei dem untersuchten Label (FallStatus mit den Ausprägungen Verstorben und Genesen) handelt es sich um ein einen BinaryClasificator. Er kann die Werte 0 und 1 annehmen. Für die Modellevaluation sind daher die BinaryClassificationMetrics zu verwenden. (Apache Spark 2021i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565cbe69-ea50-4012-825e-3b99278bf3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = predictions.select(\"prediction\", \"FallStatusIndex\").rdd.map(lambda p: [p[0], p[1]]) # Map to RDD prediction|label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e00720d-f53f-435f-a3d8-b884a65716d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanzieire das BinaryClassificationMetrics-Objekt\n",
    "metrics = BinaryClassificationMetrics(predictionAndLabels)\n",
    "\n",
    "# Fläche unter der Precision-recall Curve\n",
    "\n",
    "print(\"Area under PR = %s\" % metrics.areaUnderPR)\n",
    "\n",
    "# Fläche unter der ROC curve\n",
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a938ac6c-b3a3-43dd-b460-8d338505a28e",
   "metadata": {},
   "source": [
    "### Multiclass classification Metrics\n",
    "In den meißten Fällen können auch Multiclass Classification Metrics bei Binary Classifaction Problemen angewandt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d69e82-ba0a-4061-a6c9-1b6c58c50501",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = predictions.select(\"prediction\", \"FallStatusIndex\").rdd.map(lambda p: (p[0], p[1])) # Map to RDD prediction|label\n",
    "# Instantiate metrics object\n",
    "mcMetrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5d50a8-caca-460f-8ef4-446bb1add7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcMetrics.confusionMatrix().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0955a46c-ff81-4fe5-bbaa-b65e8658f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall statistics\n",
    "precision = mcMetrics.precision(1.0)\n",
    "recall = mcMetrics.recall(1.0)\n",
    "f1Score = mcMetrics.fMeasure(1.0)\n",
    "print(\"Summary Stats\")\n",
    "print(\"Precision = %s\" % precision)\n",
    "print(\"Recall = %s\" % recall)\n",
    "print(\"F1 Score = %s\" % f1Score)\n",
    "\n",
    "\n",
    "labels = predictions.select(\"FallStatusIndex\").rdd.map(lambda lp: lp.FallStatusIndex).distinct().collect()\n",
    "for label in sorted(labels):\n",
    "    print(\"Class %s precision = %s\" % (label, mcMetrics.precision(label)))\n",
    "    print(\"Class %s recall = %s\" % (label, mcMetrics.recall(label)))\n",
    "    print(\"Class %s F1 Measure = %s\" % (label, mcMetrics.fMeasure(label, beta=1.0)))\n",
    "\n",
    "# Weighted stats\n",
    "print(\"Weighted recall = %s\" % mcMetrics.weightedRecall)\n",
    "print(\"Weighted precision = %s\" % mcMetrics.weightedPrecision)\n",
    "print(\"Weighted F(1) Score = %s\" % mcMetrics.weightedFMeasure())\n",
    "print(\"Weighted F(0.5) Score = %s\" % mcMetrics.weightedFMeasure(beta=0.5))\n",
    "print(\"Weighted false positive rate = %s\" % mcMetrics.weightedFalsePositiveRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290309eb-6c3a-4c4d-a2e1-e8215f0f1ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e064f-c5da-4d52-b695-01f5ab7e2694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
