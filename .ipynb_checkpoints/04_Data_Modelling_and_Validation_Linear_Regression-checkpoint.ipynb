{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78da626b-7d05-4bc8-8204-27ba6c010209",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ca4d0ac4-226e-4f5b-a6fa-0bd1b85bd29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from helpers.helper_functions import translate_to_file_string\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "inputFile = translate_to_file_string(\"./data/Data_Preparation_Result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4978b0a3-e029-4a47-addf-3d03cc69e0fd",
   "metadata": {},
   "source": [
    "## Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "67da5ee7-f795-4e20-8ea6-17affdfde647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Bundesland: string (nullable = true)\n",
      " |-- BundeslandIndex: integer (nullable = true)\n",
      " |-- Landkreis: string (nullable = true)\n",
      " |-- LandkreisIndex: integer (nullable = true)\n",
      " |-- Altersgruppe: string (nullable = true)\n",
      " |-- AltersgruppeIndex: double (nullable = true)\n",
      " |-- Geschlecht: string (nullable = true)\n",
      " |-- GeschlechtIndex: double (nullable = true)\n",
      " |-- FallStatus: string (nullable = true)\n",
      " |-- FallStatusIndex: double (nullable = true)\n",
      " |-- Falldatum: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#create a SparkSession\n",
    "spark = (SparkSession\n",
    "       .builder\n",
    "       .appName(\"DataModelling\")\n",
    "       .getOrCreate())\n",
    "# create a DataFrame using an ifered Schema \n",
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "       .option(\"inferSchema\", \"true\") \\\n",
    "       .option(\"delimiter\", \";\") \\\n",
    "       .csv(inputFile)   \n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e88e9f4-6c6e-4171-b03b-c23335b53207",
   "metadata": {},
   "source": [
    "## Vorbereitung der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaafbf7-bf81-46f4-b14f-8bbdf3bb599b",
   "metadata": {},
   "source": [
    "### Filtern der Datensätze\n",
    "Für das Training dieses Modells ist es sinnvoll nur die Fälle zu betrachten, bei den der Ausgang der Corona-Erkrankung bereits bekannt ist (\"GENESEN\" oder \"GESTORBEN\"). Daher werden die Fälle mit noch erkrankten Personen herausgefiltert. Ebenfalls muss der FallStatusIndex neu vergeben werden, damit dieses Feature nur noch die Werte 0 oder 1 enthält.Dies erfolgt im nachfolgenden Abschnitt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "89cc8a37-30ad-4458-8df2-ec4da36d7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNeu = df.filter(df.FallStatus != \"NICHTEINGETRETEN\").drop(\"FallStatusIndex\").withColumnRenamed(\"FallStatus\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92173359-0c5a-432a-9442-7f7fd9f68d3e",
   "metadata": {},
   "source": [
    "### FallStatusIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f8c51fc4-9b1f-494e-807a-891dcfa54262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------+--------------+------------+-----------------+----------+---------------+-------+----------+----------+\n",
      "|Bundesland|BundeslandIndex|Landkreis|LandkreisIndex|Altersgruppe|AltersgruppeIndex|Geschlecht|GeschlechtIndex|  label| Falldatum|labelIndex|\n",
      "+----------+---------------+---------+--------------+------------+-----------------+----------+---------------+-------+----------+----------+\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-04-21|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-09-12|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-10-23|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-11-18|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-11-21|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-11-22|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-12-04|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-12-08|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-12-17|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-06|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-09|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-16|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-18|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-19|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-17|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-21|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-24|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-25|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-31|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-02-08|       0.0|\n",
      "+----------+---------------+---------+--------------+------------+-----------------+----------+---------------+-------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wollten eigentlich den Indexer mitgeben in die Pipeline. Dies führt aber zum Fehler, dass er das Label nicht kennt.\n",
    "indexer = StringIndexer(inputCol=\"label\", outputCol=\"labelIndex\")\n",
    "indexedDF = indexer.fit(dfNeu).transform(dfNeu)\n",
    "indexedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e0a06b67-fc25-4dcc-9b6b-60f2193be7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------+--------------+------------+-----------------+----------+---------------+-------+----------+----------+\n",
      "|Bundesland|BundeslandIndex|Landkreis|LandkreisIndex|Altersgruppe|AltersgruppeIndex|Geschlecht|GeschlechtIndex|  label| Falldatum|labelIndex|\n",
      "+----------+---------------+---------+--------------+------------+-----------------+----------+---------------+-------+----------+----------+\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-04-21|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-09-12|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-10-23|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-11-18|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-11-21|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-11-22|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-12-04|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-12-08|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2020-12-17|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-06|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-09|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-16|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-18|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-19|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-17|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-21|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-24|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-25|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-01-31|       0.0|\n",
      "| Thüringen|             16| LK Gotha|         16067|     A00-A04|              5.0|         W|            0.0|GENESEN|2021-02-08|       0.0|\n",
      "+----------+---------------+---------+--------------+------------+-----------------+----------+---------------+-------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexedDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafcf0db-a2db-4f4f-ace8-42856bc71989",
   "metadata": {},
   "source": [
    "### Aufbau des Feature-Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "37860d4a-f3ba-4fc8-896c-f23531f5f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler =  VectorAssembler(outputCol=\"features\", inputCols=[\"GeschlechtIndex\",\"AltersgruppeIndex\",\"LandkreisIndex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcf4042-b966-403e-b8c6-741ef1ead0c2",
   "metadata": {},
   "source": [
    "### Splitten in Trainings und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3a012b41-d413-4b3b-a997-2e631d56204b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------+-----------+--------------+------------+-----------------+----------+---------------+---------+----------+----------+\n",
      "|       Bundesland|BundeslandIndex|  Landkreis|LandkreisIndex|Altersgruppe|AltersgruppeIndex|Geschlecht|GeschlechtIndex|    label| Falldatum|labelIndex|\n",
      "+-----------------+---------------+-----------+--------------+------------+-----------------+----------+---------------+---------+----------+----------+\n",
      "|Baden-Württemberg|              8|LK Biberach|          8426|     A35-A59|              0.0|         M|            1.0|GESTORBEN|2021-03-29|       1.0|\n",
      "|Baden-Württemberg|              8|LK Biberach|          8426|     A35-A59|              0.0|         M|            1.0|GESTORBEN|2021-04-11|       1.0|\n",
      "|Baden-Württemberg|              8|LK Biberach|          8426|     A35-A59|              0.0|         M|            1.0|GESTORBEN|2021-04-11|       1.0|\n",
      "|Baden-Württemberg|              8|LK Biberach|          8426|     A35-A59|              0.0|         M|            1.0|GESTORBEN|2021-04-24|       1.0|\n",
      "|Baden-Württemberg|              8|LK Biberach|          8426|     A35-A59|              0.0|         M|            1.0|GESTORBEN|2021-05-07|       1.0|\n",
      "|Baden-Württemberg|              8|LK Biberach|          8426|     A60-A79|              2.0|         M|            1.0|GESTORBEN|2020-03-03|       1.0|\n",
      "|Baden-Württemberg|              8|LK Biberach|          8426|     A60-A79|              2.0|         M|            1.0|GESTORBEN|2020-03-12|       1.0|\n",
      "|Baden-Württemberg|              8|LK Biberach|          8426|     A60-A79|              2.0|         M|            1.0|GESTORBEN|2020-03-20|       1.0|\n",
      "|Baden-Württemberg|              8|LK Biberach|          8426|     A60-A79|              2.0|         M|            1.0|GESTORBEN|2020-03-20|       1.0|\n",
      "|Baden-Württemberg|              8|LK Biberach|          8426|     A60-A79|              2.0|         M|            1.0|GESTORBEN|2020-04-07|       1.0|\n",
      "+-----------------+---------------+-----------+--------------+------------+-----------------+----------+---------------+---------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits = indexedDF.randomSplit([0.8, 0.2 ], 345678)\n",
    "trainingVector = splits[0]\n",
    "testVector = splits[1]\n",
    "\n",
    "trainingVector.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a136e3f2-1007-4f62-9f35-d52869cd842c",
   "metadata": {},
   "source": [
    "## Modellierung\n",
    "### Linear-Regression-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5006ea64-b3dc-4658-9b12-ab1b2e16ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"labelIndex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d5034e-f0cc-4e55-ba25-1482b964d471",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "030efbf4-d50a-4fc9-8448-61314a82c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9b0dab-06d4-4d34-851c-558dcac729e2",
   "metadata": {},
   "source": [
    "### Parametertuning\n",
    "Eine wichtige Aufgabe beim Machine Learning ist die Auswahl des geeigneten Modells bzw. die passenden Paramter für ein Modell herauszufinden. Letzteres wird auch Parametertuning genannt. Die in Pyspark enthaltene MLLib bietet speziell hierfür ein entsprechende Tooling. Und zwar kann ein CrossValidator bzw. ein TrainValidationSplit verwendet werden. Voraussetzung sind ein Estimator (ein Modell oder eine Pipeline), ein Paramter-Grid und eine Evaluator. Dies ist auch im Zusammenhang mit dem Thema Cross-Validation zu sehen. (Apache Spark 2020a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2a4a1571-498e-4d42-8f08-05500cacf6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.maxIter, [1,10, 100]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr.fitIntercept, [False, True])\\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431859e4-d239-447c-bf75-6f8437a36d82",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "Wie eben erwähnt, benötigt der Cross-Validator einen Evaluator. Letzterer ist zu wählen, abhängig von dem jeweilligen Modell. In diesem Fall muss ein RegressionEvaluator angewendet werden. (Apache Spark 2020a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7df713c9-41e8-4492-bcc5-77e3f5799d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition des Cross-Validators \n",
    "# num-Folds gibt an in wie viele Datensatz-Paare die Datensätze aufgeteilt werden.\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator(),\n",
    "                          numFolds=3)  # use 3+ folds in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1efc88e-ebaa-4ada-befe-86ed11887356",
   "metadata": {},
   "source": [
    "#### Durchführung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e278a6a5-2976-411c-83bf-81d1227e4d43",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Column label must be of type numeric but was actually of type string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-d0eb45c67c75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Anpassung des Modells und Auswahl der besten Parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcvModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingVector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36msingleTask\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m#  `MetaAlgorithmReadWrite.getAllNestedStages`, make it return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m#  all nested stages and evaluators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModel\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \"\"\"\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Column label must be of type numeric but was actually of type string."
     ]
    }
   ],
   "source": [
    "# Anpassung des Modells und Auswahl der besten Parameter\n",
    "cvModel = crossval.fit(trainingVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7acaa7a-23f6-4d6c-a4ba-46ccf15dbe34",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75082263-72e3-4233-a04e-9bf1c05dc473",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cvSVMModel.transform(test)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2386f37f-6720-412e-829c-275d0af3a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"FallStatusIndex\",predictionCol=\"prediction\", metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e8aba-5d9e-42cb-85e0-d8c0ce7942ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"root mean square error = \" , evaluator.evaluate(predictionsLR))\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b351232-6ba5-4be1-a27e-b0871636d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the Coefficients and Intercept\n",
    "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "print(\"Intercept: %s\" % str(lrModel.intercept))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
